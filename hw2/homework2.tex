\documentclass[]{article}

%opening
\title{FML Fall 2015 HW 2}
\author{David Kasofsky}

\usepackage{amsmath}

\usepackage{amssymb}

\usepackage{fancyhdr}

\pagestyle{fancy}
\lhead{David Kasofsky - FML Fall 2015 HW 2}

\renewcommand{\thesection}{\Alph{section}}
\renewcommand{\thesubsubsection}{\Alph{subsubsection}}

\begin{document}

\section{}
\subsection{}
As in the related homework problem, we can think of this as a neural network with one input node, $T$ internal nodes, and one output node. At each internal node, we may select a function from $H$ and so the growth function is $\Pi_H(m)$. At the output node we have some growth function $\Pi_O(m)$. Thus the overall growth function is $\Pi_H(m)^T\Pi_O(m)$ as there are $T$ internal nodes leading to the single output node. We can use Sauer's Lemma to bound the growth function in terms of the VC-dimension. Note the the output node defines a $T$-dimensional hyperplane and so has VC-dimension $T+1$. So:\\

$\Pi_O(m) \le (\frac{e m}{T+1})^{T+1}$\\

and:\\ 

$\Pi_H(m)^T \le (\frac{e m}{d})^{dT} $\\

where $d$ is the VC-dimension of $H$. Continuing we have:\\

$\Pi_H(m)^T\Pi_O(m) \le (\frac{e m}{T+1})^{T+1} (\frac{e m}{d})^{dT}$\\

$= (e m)^{dT+T+1} (\frac{1}{T+1})^{T+1} (\frac{1}{d})^{dT} \le (e m)^{dT+T+1}$\\

Now, let $m = 2(dT+T+1)log_2((dT+T+1)e)$. By the inequality in the hint of the related homework problem and $T > 1 \implies (dT+T+1)e > 4$, we have:\\

$m \ge (dT+T+1) log_2(e m) \implies 2^m \ge (e m)^{(dT+T+1)}$\\

And so the VC-dimension of $H$ is less than
\begin{center}
	$2(dT+T+1)log_2((dT+T+1)e)$
\end{center}

\pagebreak

\section{}
\subsection{}
\subsection{}

Consider $C(m+1,d)=C(m,d) + C(m,d-1)$. $C(m,d)$ is the number of linearly separable labelings (LSLs) of $m$ points. Now consider a new point $x_{m+1}$. It is still possible to generate $C(m,d)$ LSLs of the $m+1$ points. Let $L$ be some LSL of the original $m$ points. If it is possible to generate $L$ using a hyperplane through $x_{m+1}$, then we know we can label $x_{m+1}$ either positively or negatively by the result of the previous question. If we cannot generate $L$ with a hyperplane through $x_{m+1}$, then any hyperplane that generates $L$ will label $x_{m+1}$ in some way. This shows that $C(m+1,d) \ge C(m,d)$.

To show that $x_{m+1}$ gives rise to exactly $C(m,d-1)$ additional LSLs, consider the case in which $L$ can be generated by a hyperplane through $x_{m+1}$. 

We can still create $C(m,d)$ linearly separable labelings of the $m+1$ points. However, if is possible to generate any of the $C(m,d)$ labellings with a hyperplane that passes through $x_{m+1}$, then we generate an additional labeling by the result of the previous section since we may label $x_{m+1}$ either positively or negatively while retaining our original labeling. The number of ways in which this is possible is $C(m,d-1)$ because we can project onto the hyperplane defined by the vector $x_{m+1}$. 

\end{document}